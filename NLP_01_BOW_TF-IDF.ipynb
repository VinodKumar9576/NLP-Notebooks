{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "name": "NLP_01_BOW_TF-IDF.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/biku1998/NLP-Notebooks/blob/master/NLP_01_BOW_TF-IDF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QV--I6404IOV",
        "colab_type": "text"
      },
      "source": [
        "### In this notebook we will see the most basic topic in NLP i.e how do we represent words into numerical format.\n",
        "\n",
        "* The story of NLP starts with a document. These are nothing but terms used for representing a piece of text. Can be a simple string, can be large book. Another term that you can hear is corpus which means a collection of such documents."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spRmH4zA4IOW",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "**Bag of Words**\n",
        "\n",
        "Steps to create Bag of Words\n",
        "\n",
        "- Construct a set of all the words you have in your corpus. why set ? --> no duplicates\n",
        "- Each word in the set is a different dimension.\n",
        "- Each line or sentence in your data will be a vector or list in very simple terms of size (1,no_of_unique_words_in_corpus) or (1,len(set)). So each index i will represent a word.\n",
        "- And the element at that index will be = # times the word occurs in the given line or sentence.\n",
        "\n",
        "e.g\n",
        "\n",
        "A man is running in a park --> [0 ,1 ,0 ,0 ,0 , 0 ,1 ,0 ,2 0, 0 ,1........]\n",
        "                                \n",
        "    1-(man appeared 1 time)     1-(running appeared 1 time)   2-(a){a appeared 2 times}     1-(park appeared 1 time) ....\n",
        "\n",
        "**Some points about Bag Of Words**\n",
        "- as you can see as the size of corpus increases the size of each vector representing a line increases\n",
        "- the vector is very sparse i.e most of the values are zero\n",
        "- bag of words does not capture semantic of a text, we can see that it's doing nothing but counting common words.\n",
        "\n",
        "---\n",
        "\n",
        "**Binary or boolean Bag of Words**\n",
        "- It's same as bag of words but instead of putting the no of occurrence it simply put 1 if the word exist else 0\n",
        "- So binary bag of words can be thought of as no of differing words\n",
        "\n",
        "\n",
        "**Let's see how to implement both in pure python**\n",
        "\n",
        "I will try my best to follow best coding practices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekX_CslK4IOY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5frjBM14IOe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########### Bag of Words\n",
        "\n",
        "class BagOfWords(object):\n",
        "    def __init__(self,corpus:list):\n",
        "        if not isinstance(corpus,list):\n",
        "            raise Exception(f\"corpus type should be a list of documents i.e strings not {type(corpus)}\")\n",
        "        self.corpus_len = len(corpus)\n",
        "        self.unique_words = set()\n",
        "        self.corpus = corpus # don't do this if the corpus is large otherwise your RAM usage will incerease        \n",
        "        self.construct_corpus()\n",
        "    \n",
        "    def construct_corpus(self):\n",
        "        for document in self.corpus:\n",
        "            tokens = document.split(\" \")\n",
        "            for t in tokens:\n",
        "                self.unique_words.add(t.strip())\n",
        "                \n",
        "    def get_numeric_rep(self,document:str):\n",
        "        if not isinstance(document,str):\n",
        "            raise Exception(f\"document must be string not {type(document)}\")\n",
        "        word_dict = dict.fromkeys(self.unique_words,0)\n",
        "        \n",
        "        for word in document.split(\" \"):\n",
        "            word_dict[word.strip()] += 1\n",
        "            \n",
        "        return np.array(list(word_dict.values()))\n",
        "    \n",
        "############ Binary Bag of Words\n",
        "\n",
        "class BinaryBagOfWords(object):\n",
        "    def __init__(self,corpus:list):\n",
        "        if not isinstance(corpus,list):\n",
        "            raise Exception(\"corpus type should be a list of documents i.e strings\")\n",
        "        self.corpus_len = len(corpus)\n",
        "        self.unique_words = set()\n",
        "        self.corpus = corpus # don't do this if the corpus is large otherwise your RAM usage will incerease        \n",
        "        self.construct_corpus()\n",
        "    \n",
        "    def construct_corpus(self):\n",
        "        for document in self.corpus:\n",
        "            tokens = document.split(\" \")\n",
        "            for t in tokens:\n",
        "                self.unique_words.add(t.strip())\n",
        "                \n",
        "    def get_numeric_rep(self,document:str):\n",
        "        if not isinstance(document,str):\n",
        "            raise Exception(\"document must be string\")\n",
        "        word_dict = dict.fromkeys(self.unique_words,0)\n",
        "        \n",
        "        for word in document.split(\" \"):\n",
        "            word_dict[word.strip()] = 1\n",
        "            \n",
        "        return np.array(list(word_dict.values()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUhFy7UP4IOh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's take 2 simple document\n",
        "\n",
        "docA = \"the cat is sitting on my face\"\n",
        "docB = \"the dog is sitting on my bed\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pDk6U2l4IOk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bow  = BagOfWords([docA,docB])\n",
        "bow_binary = BinaryBagOfWords([docA,docB])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52tyc8km4IOn",
        "colab_type": "code",
        "colab": {},
        "outputId": "e302580d-a954-4b38-fa67-075ac008a9f7"
      },
      "source": [
        "bow.corpus_len,bow_binary.corpus_len # 2 documents"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbvAhCv14IOs",
        "colab_type": "code",
        "colab": {},
        "outputId": "8f215bf6-574c-4892-b2fb-ab0797b9d63c"
      },
      "source": [
        "bow.unique_words,bow_binary.unique_words"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'bed', 'cat', 'dog', 'face', 'is', 'my', 'on', 'sitting', 'the'},\n",
              " {'bed', 'cat', 'dog', 'face', 'is', 'my', 'on', 'sitting', 'the'})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxJ3140E4IOw",
        "colab_type": "code",
        "colab": {},
        "outputId": "44dd37f4-7e56-457b-d04a-827b6ddbb98f"
      },
      "source": [
        "bow.get_numeric_rep(docA)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, 1, 1, 1, 1, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thbar3xB4IO0",
        "colab_type": "code",
        "colab": {},
        "outputId": "34d86141-93c6-443b-84ca-efec897f70f6"
      },
      "source": [
        "bow_binary.get_numeric_rep(docA)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, 1, 1, 1, 1, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3L2T6FXC4IO6",
        "colab_type": "code",
        "colab": {},
        "outputId": "2ce2a46f-805c-492a-899d-7a6866a00809"
      },
      "source": [
        "docTest = \"the cat is sitting on my face the cat is\"\n",
        "bow.get_numeric_rep(docTest) # the elements are freq of words"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, 2, 2, 2, 1, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00mk-mfL4IO9",
        "colab_type": "code",
        "colab": {},
        "outputId": "950ec2e3-2b3a-4b9c-9dca-c718e1e9cf26"
      },
      "source": [
        "bow_binary.get_numeric_rep(docTest) # the elements are just binary value i.e word exist or not"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, 1, 1, 1, 1, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85UXJySZ4IPA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# let's compare the numerical conversion of 2 documents carefully\n",
        "\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oL8hZYmv4IPE",
        "colab_type": "code",
        "colab": {},
        "outputId": "cb3aacf6-8545-4252-fef6-9f392be9adbf"
      },
      "source": [
        "print(docA)\n",
        "print(docB)\n",
        "pd.DataFrame(columns = bow.unique_words,data = [bow.get_numeric_rep(docA),bow.get_numeric_rep(docB)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the cat is sitting on my face\n",
            "the dog is sitting on my bed\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>face</th>\n",
              "      <th>my</th>\n",
              "      <th>bed</th>\n",
              "      <th>cat</th>\n",
              "      <th>is</th>\n",
              "      <th>the</th>\n",
              "      <th>sitting</th>\n",
              "      <th>dog</th>\n",
              "      <th>on</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   face  my  bed  cat  is  the  sitting  dog  on\n",
              "0     1   1    0    1   1    1        1    0   1\n",
              "1     0   1    1    0   1    1        1    1   1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bb2NLb5p4IPH",
        "colab_type": "text"
      },
      "source": [
        "**Observations**\n",
        "\n",
        "- if we see words like a, the, is etc are pretty common words and they occur in both documents\n",
        "- The problem with BOW is we are using too much words which don't mean much .i.e those words don't help to differentiate those 2 documents we have hence they are often called **stop words**\n",
        "\n",
        "\n",
        "- So in any language the words mostly follow power law distribution. If we use this count based approach then we will end up with a lot of words that do not contain a lot of information.\n",
        "- Hence they will end up hurting the performance of **simpler models** like Naive Bayes etc.\n",
        "- In more capable networks like Neural Network these words are not removed because they can through context sometimes, this is why common text cleaning are not advised when using large architectures\n",
        "\n",
        "- **Sometime we also remove stop-words , do stemming , lemmatization (we will cover later) before building Bag of words** So that we get good quality of numerical rep.\n",
        "\n",
        "**Look at this interesting case of guy using RNN for text classification using Fast.ai library**\n",
        "\n",
        "<img src = \"./twitter_stop_words.png\"></img>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ere_kFD4IPH",
        "colab_type": "text"
      },
      "source": [
        "### Hmm so we need a better way to handle our numerical conversion process\n",
        "\n",
        "    \n",
        "---\n",
        "**TF-IDF** (term frequency - inverse document frequency)\n",
        "\n",
        "**TF**\n",
        "\n",
        "$TF(w_i,d_j) = \\frac{no ~of ~times ~w_i ~occurs ~in ~d_j}{total ~no ~of ~words ~in ~d_j}$ \n",
        "\n",
        "In words\n",
        " - Term freq of any word $w_i$ in a document $d_j$ is equal to no time word $w_i$ occurs in document $d_j$ by total no of words in document $d_j$\n",
        " \n",
        "Some key points\n",
        " - $ 0 \\leq TF(w_i,d_j) \\leq 1$ Hence we can interpret it as probabilities so term freq says \"**what is the probability of finding a word in a document**\". The other way to say this is \"**how often does a word occurs in a document**\"\n",
        "- So the more often the word occurs the higher the term frequency and vice versa\n",
        " \n",
        "- fun fact : all of these bag of words, Tf-Idf were first discovered in information retrieval branch of NLP\n",
        "---\n",
        "\n",
        "**IDF**\n",
        "\n",
        "$IDF(w_i,D_c)=\\log(\\frac{N ~(total ~no ~of ~documents)}{n_i~(documents ~which ~contain ~w_i) })$ where $w_i$ is i'th word and $D_c$ corpus of documents\n",
        "\n",
        "Some pointers regarding tf-idf\n",
        "- $n_i \\leq N$  ==>  $\\frac{N}{n_i}\\geq 1$  ==> $\\log(\\frac{N}{n_i}) \\geq 0$, so IDF is always positive\n",
        "- **But when IDF will be equal to 1 ?**\n",
        "\n",
        "Let's figure it out\n",
        "\n",
        "Suppose $n_i$ increases which will result in decrease of $\\frac{N}{n_i}$ Which will result in decrease of  $\\log(\\frac{N}{n_i})$ because log is **monotonically increasing function**, what the hell is this ? -> When $f(x)$ increases as $x$ increases, this type of function is called monotonically increasing fn. For more info <a href = \"https://en.wikipedia.org/wiki/Monotonic_function\">here </a>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kt54DMIf4IPI",
        "colab_type": "code",
        "colab": {},
        "outputId": "569e8782-7292-49b1-8b05-6cda6e3e29fd"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = np.linspace(1,100,1000)\n",
        "y = np.log(x)\n",
        "\n",
        "plt.plot(x,y)\n",
        "plt.title(\"monotonically increasing $\\log(x)$ plot\",fontsize = 15)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-BbLzqT4IPL",
        "colab_type": "text"
      },
      "source": [
        "So we now know if a word $w_i$ occurs in almost all the document the IDF of that word will be very low.\n",
        "Which is nothing but if $n_i\\uparrow$ then $IDF\\downarrow$ \n",
        "\n",
        "Can you guess some words that will reflect the above case ? Yes.. **All the stop words**\n",
        "\n",
        "And and if  $n_i\\downarrow$ then $IDF\\uparrow$\n",
        "\n",
        "Can you guess some words that will reflect the above case ? Yes.. **All the rare words**\n",
        "\n",
        "**Okay Let's combine Tf and Idf to see how we will achieve our task of converting words to numerical forms**\n",
        "\n",
        "---\n",
        "Suppose a sentence \"A man is running in the park\" will be represented as follows $[w_1,w_2,w_3,w_4,w_5,w_6,w_7]$ where $w_i$ is a word in the sentence and we will replace $w_i$ with $TF(w_i,d_j) * IDF(w_i,D_c)$\n",
        "\n",
        "But what does this mean ? \n",
        "\n",
        "When will $TF(w_i,d_j)$ be high ? --> When word will occur more frequent\n",
        "and when will $IDF(w_i,D_c)$ be high ? --> when a word is rare \n",
        "\n",
        "Ohh which means **We are giving more importance to rare words**\n",
        "\n",
        "**But still TF-IDF does not take semantic meaning of words in consideration**\n",
        "\n",
        "    Okay Time to code Tf-Idf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKONITvK4IPL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Tf_Idf(object):\n",
        "    def __init__(self,corpus:list):\n",
        "        if not isinstance(corpus,list):\n",
        "            raise Exception(f\"corpus type should be a list of documents i.e strings not {type(corpus)}\")\n",
        "        self.corpus_len = len(corpus)\n",
        "        self.corpus = corpus\n",
        "        self.unique_words = set()\n",
        "        self.construct_corpus()\n",
        "        \n",
        "    def construct_corpus(self):\n",
        "        for document in self.corpus:\n",
        "            tokens = document.split(\" \")\n",
        "            for t in tokens:\n",
        "                self.unique_words.add(t.strip())\n",
        "                \n",
        "    def tf(self,word:str,document:str,verbose = False):\n",
        "        words = document.split(\" \")\n",
        "        words = [w.strip() for w in words]\n",
        "        word = word.strip()\n",
        "        \n",
        "        if not word in words:\n",
        "            return 0\n",
        "        \n",
        "        word_dict = dict.fromkeys(words,0)\n",
        "        \n",
        "        for w in words:\n",
        "            word_dict[w] += 1\n",
        "            \n",
        "        tf = word_dict[word] / len(words)\n",
        "        \n",
        "        if verbose:\n",
        "            print(f\"word provided : {word}\\nDocument provided : {document}\\ntf form : {tf}\")\n",
        "        return tf\n",
        "    \n",
        "    def idf(self,word):\n",
        "        word = word.strip()\n",
        "        total_docs = self.corpus_len\n",
        "        word_counter = 0\n",
        "        \n",
        "        for doc in self.corpus:\n",
        "            words = doc.split(\" \")\n",
        "            words = [w.strip() for w in words]\n",
        "            \n",
        "            if word in words:\n",
        "                word_counter +=1\n",
        "        \n",
        "        return np.log(total_docs / word_counter)\n",
        "        \n",
        "        \n",
        "                \n",
        "    def get_numeric_rep(self,document:str):\n",
        "        if not isinstance(document,str):\n",
        "            raise Exception(f\"document must be string not {type(document)}\")\n",
        "        \n",
        "        num_rep = dict.fromkeys(self.unique_words,0)\n",
        "        \n",
        "        for w in self.unique_words:\n",
        "            tf = self.tf(w,document)\n",
        "            idf = self.idf(w)\n",
        "            num_rep[w] = tf * idf\n",
        "            \n",
        "        return np.array(list(num_rep.values()))\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNZyWFUZ4IPP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf_idf = Tf_Idf([docA,docB])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bP4PDIxp4IPS",
        "colab_type": "code",
        "colab": {},
        "outputId": "ac8d5424-9cd9-4cdd-89e7-c7b0fd10b82c"
      },
      "source": [
        "tf_idf.get_numeric_rep(docA)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.09902103, 0.        , 0.        , 0.09902103, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoTSwEyu4IPW",
        "colab_type": "code",
        "colab": {},
        "outputId": "f81cbe0b-92b5-4c50-8689-a7542b348244"
      },
      "source": [
        "tf_idf.get_numeric_rep(docB)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.        , 0.09902103, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.09902103, 0.        ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OP5GYKuU4IPZ",
        "colab_type": "code",
        "colab": {},
        "outputId": "d87003a6-fd6b-420f-d12b-5dcb3415156a"
      },
      "source": [
        "tf_idf.idf(\"the\") # idf of commom word"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZJMt-qN4IPd",
        "colab_type": "code",
        "colab": {},
        "outputId": "57d11260-1046-4c40-f0a8-f326ba628968"
      },
      "source": [
        "tf_idf.idf(\"cat\") # idf of rare word"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6931471805599453"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-V4aD90X4IPf",
        "colab_type": "code",
        "colab": {},
        "outputId": "a582d739-f4cb-4b70-a2bc-d4b5c6805c1b"
      },
      "source": [
        "print(docA)\n",
        "print(docB)\n",
        "pd.DataFrame(columns = tf_idf.unique_words,data = [tf_idf.get_numeric_rep(docA),tf_idf.get_numeric_rep(docB)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the cat is sitting on my face\n",
            "the dog is sitting on my bed\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>face</th>\n",
              "      <th>my</th>\n",
              "      <th>bed</th>\n",
              "      <th>cat</th>\n",
              "      <th>is</th>\n",
              "      <th>the</th>\n",
              "      <th>sitting</th>\n",
              "      <th>dog</th>\n",
              "      <th>on</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.099021</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.099021</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.099021</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.099021</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       face   my       bed       cat   is  the  sitting       dog   on\n",
              "0  0.099021  0.0  0.000000  0.099021  0.0  0.0      0.0  0.000000  0.0\n",
              "1  0.000000  0.0  0.099021  0.000000  0.0  0.0      0.0  0.099021  0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1L9d3aW94IPh",
        "colab_type": "code",
        "colab": {},
        "outputId": "14ab998f-f001-4b5a-d8ab-cb8eb581becf"
      },
      "source": [
        "docA = \"the cat sat on my face\"\n",
        "docB = \"the dog sat on my bed\"\n",
        "\n",
        "print(docA)\n",
        "print(docB)\n",
        "pd.DataFrame(columns = tf_idf.unique_words,data = [tf_idf.get_numeric_rep(docA),tf_idf.get_numeric_rep(docB)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the cat sat on my face\n",
            "the dog sat on my bed\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>face</th>\n",
              "      <th>my</th>\n",
              "      <th>bed</th>\n",
              "      <th>cat</th>\n",
              "      <th>is</th>\n",
              "      <th>the</th>\n",
              "      <th>sitting</th>\n",
              "      <th>dog</th>\n",
              "      <th>on</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.115525</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.115525</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.115525</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.115525</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       face   my       bed       cat   is  the  sitting       dog   on\n",
              "0  0.115525  0.0  0.000000  0.115525  0.0  0.0      0.0  0.000000  0.0\n",
              "1  0.000000  0.0  0.115525  0.000000  0.0  0.0      0.0  0.115525  0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xxq6OYID4IPk",
        "colab_type": "text"
      },
      "source": [
        "**Observations**\n",
        "- We can clearly see the power of tf idf all the stop words i.e. words that are not important to separate the 2 sentences are just 0\n",
        "- This why tf-idf makes more sense, instead of just blunt count we are using probabilities\n",
        "\n",
        "---\n",
        "\n",
        "- **Notice that we have tried to make the class signature of both the approach same. It is generally a good practice to keep the structure of your code same when you are developing different methods for same task**\n",
        "\n",
        "- **By the way we don't need to implement TF-IDF or BOW from scratch, they are already there in sklearn and other ml tools. But to get a good understanding of this fundamentals we should do it.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSChwX5R4IPk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}